---
output: 
  pdf_document:
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    number_sections: true
    toc: true
    toc_depth: 4
title: "Project I: SEMMA with Regularized Logistic Regression"
author: 
- Appiah Prince^[pappiah@miners.utep.edu]
- University of Texas at El Paso (UTEP) 
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontsize: 12pt
spacing: single
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsfonts}
- \usepackage{amsthm}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \rhead{STAT 5494-- Statistical Machine Learning}
- \lhead{SEMMA with Regularized Logistic Regression}
- \cfoot{\thepage}
- \usepackage{algorithm}
- \usepackage[noend]{algpseudocode}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\section{Bring in the data}
```{r}
diabetes <- read.csv("diabetes_data_upload.csv") 
dim(diabetes)
names(diabetes) 
head(diabetes) 
```

\
 REMARKS
 
- There are **520** observations and **17** variables.


\section{Exploratory Data Analysis(EDA)}
```{r}
str(diabetes) # checking for variable types
```



\
Remarks

- Age is numeric variable while the remaining **16** variables are character
 variables.

```{r}
# INSPECT THE DISTINCT VALUES OF EACH X
cols <- 1:NCOL(diabetes)
for (j in cols){
  x <- diabetes[,j]
  print(names(diabetes)[j])
  print(sort(unique(x, incomparables=TRUE)))
  print(table(x, useNA="ifany"))
}
```






\subsection{Frequency Distribution of the target variable class}
```{r}
t <- table(diabetes$class, useNA="ifany")
freq_dist <- as.data.frame(t)
colnames(freq_dist) <- c("class", "frequency")
freq_dist
```

\
Remarks

- There are **320** patients that their diabetes diagnosis is positive while **200** patients are diagnose negative. So, there is an unequal distribution of the results of the diagnosis. Hence, we have a slightly unbalanced classification problem.


\subsection{Missing Values}
```{r}
library(questionr)
freq.na(diabetes)
```

\
Remarks

There are no missing values in the dataset.


```{r}
# Assigning 0 for Negative class and 1 for Positive class
diabetes$class <- ifelse(diabetes$class=="Negative", 0,1)

```


\section{Variable Screening}

```{r}
# Two sample t-test
cond.1 <- diabetes$class == 1
cond.2 <- as.vector(which(sapply(diabetes[,-c(17)], is.numeric), arr.ind = T))
print("Test of Normality of the numerical variables for patients diagnosed 
      diabetes postive")
shapiro.test(diabetes[cond.1, cond.2])
```


```{r}
print("Test of Normality of the numerical variables for patients diagnosed 
      diabetes Negative")
shapiro.test(diabetes[!cond.1, cond.2])
```

\
Remarks

- For the numerical variables, we first use Shapiro-Wilk test to check the 
   assumption of normality so as to know whether to use parametric or 
   nonparametric approach for the two sample t-test.We see from the output of 
   the Shapiro-Wilk normality test that the assumption of normality is violated 
   since the p-values are less than 0.05 in each group.Thus, we use the Wilcoxon     rank-sum test.



\subsection{Chisq test and Wilcoxon test}

```{r}
suppressPackageStartupMessages(library(car)) 
vars.nominal <- c("Gender","Polyuria","Polydipsia","sudden.weight.loss",
                  "weakness","Polyphagia","Genital.thrush","visual.blurring",
                  "Itching","Irritability","delayed.healing","partial.paresis",
                  "muscle.stiffness","Alopecia","Obesity")
cols.x <- 1:(NCOL(diabetes)-1)
xnames <- names(diabetes)[cols.x]
y <- diabetes$class
OUT <- NULL
for (j in 1:length(cols.x)){
  x <- diabetes[, cols.x[j]]
  xname <- xnames[j]
  if (is.element(xname, vars.nominal)){
    tbl <- table(x, y)
    pvalue <- chisq.test(tbl)$p.value
  } else {
    # WILCOXON TEST
    pvalue <- wilcox.test(x~y, alternative="two.sided")$p.value
  }
  OUT <- rbind(OUT, cbind(xname=xname, pvalue=pvalue))
}
OUT <- as.data.frame(OUT, stringsAsFactors =F)
colnames(OUT) <- c("name", "pvalue")
OUT
```

\ 
Remarks

- The predictors variables **itching**, **delayed.healing**  and **obesity** 
  have relatively higher p-values as compared to the other predictor variables.

\subsection{Non Significant Variables}
```{r}
cond.3 <- as.numeric(OUT$pvalue) > 0.25
OUT[cond.3, ]
```


\
Remarks

- The predictor variables **Itching** and **delayed.healing** are unimportant predictors given the liberal threshold significance level of 
**0.25**. Therefore, we remove the predictor variables **Itching** and 
**delayed.healing** from the data.


\subsection{Correlation plot among the variables}
```{r}
library(GoodmanKruskal)
data <- GKtauDataframe(diabetes)
plot(data, corColors = "magenta")
```


\ 
Remarks

- We observe that there is no high correlation among the variables that is no 
 high multicollinearity.


\subsection{Removing non significant variables}
```{r}
diabetes <- diabetes[, -c(10, 12)]
names(diabetes)
```





\section{Data Partition}
```{r}
set.seed(123)
n <- NROW(diabetes)
ratio <- 2/3
id.training <- sample(1:n, size=n*ratio, replace=FALSE) 
D1 <- diabetes[id.training, ]  # training data
D2 <- diabetes[-id.training, ]  # test data
dim(D1)
dim(D2)
```


\ 
Remarks

- The training data has 346 observations and 15 variables

- The test data has 174 obseervations and 15 variables


\section{Logistic Regression Modeling}
```{r}
set.seed(123)
library(ncvreg); 
y <- D1$class
formula0<- class ~.
X <- model.matrix(as.formula(formula0), data=D1)
cvfit.lasso <- cv.ncvreg(X=X,y=y, nfolds=5, family="binomial",
            penalty="lasso",lambda.min=.0001, nlambda=500,eps=.01,
            max.iter=1000) 
plot(cvfit.lasso)
```


\
Remarks

- The graph shows that 12 variables must be selected as important predictor    variables.

\subsection{Selecting the best tuning parameter}
```{r}
cvfit.lasso$lambda.min
```

\
Remarks

- We used the minimum cross-validation error as a criteria for selecting best 
tuning parameter.

\subsection{Important Predictor Variables}
```{r}
result.lasso <- cvfit.lasso$fit
beta.hat <- as.vector(result.lasso$beta[-1, cvfit.lasso$min])
cutoff <- 0
terms <- colnames(X)[abs(beta.hat) > cutoff]
terms  
```


\subsection{Final Best Model Fit}
```{r}
formula01 <- class ~ Age + Gender + Polyuria + Polydipsia + 
          sudden.weight.loss + Polyphagia + Genital.thrush + Irritability +               partial.paresis + muscle.stiffness + Alopecia + Obesity

formula.lasso <- as.formula(formula01)
fit.lasso <- glm(formula.lasso, data = D1, family="binomial")
summary(fit.lasso)
```


\
Remarks

- The AIC for the final model is somehow smaller which is good
- Most of the predictor variables are statistically significant considering 
  their p-values.



\section{Model Assessment/Deployment}

\subsection{Applying the final logistic model to the test data D2}
```{r}
yobs <- D2$class
phat <- predict(fit.lasso, newdata=D2, type="response")
cutoff <- 0.5
yhat <- (phat <= cutoff) + 0
table(yobs, yhat)
```





\subsection{ROC CURVE AND AUC}
```{r}
suppressPackageStartupMessages(library(verification))
a.ROC <- roc.area(obs=yobs, pred=phat)$A
print(a.ROC) 

suppressPackageStartupMessages(library(cvAUC))
AUC <- ci.cvAUC(predictions=phat, labels=yobs, folds=1:NROW(D2), confidence=0.95); AUC 
auc.ci <- round(AUC$ci, digits=3)

suppressPackageStartupMessages(library(verification))
mod.glm <- verify(obs=yobs, pred=phat) 
roc.plot(mod.glm, plot.thres = NULL)
text(x=0.7, y=0.2, paste("Area under ROC =", round(AUC$cvAUC, digits=3), 
	"with 95% CI (", auc.ci[1], ",", auc.ci[2], ").",
	sep=" "), col="blue", cex=1.2)
```


\
Remarks

- The area under the ROC curve is **0.959** and its confidence interval is
(0.930, 0.987)





