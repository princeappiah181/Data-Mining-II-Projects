---
output: 
  pdf_document:
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    number_sections: true
    toc: true
    toc_depth: 4
title: "Project III: Kernel PCA and Association Rule"
author: 
- Appiah Prince^[pappiah@miners.utep.edu]
- University of Texas at El Paso (UTEP) 
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontsize: 12pt
spacing: single
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsfonts}
- \usepackage{amsthm}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \rhead{STAT 5494-- Statistical Machine Learning}
- \lhead{Optimization and Kernel Trick}
- \cfoot{\thepage}
- \usepackage{algorithm}
- \usepackage[noend]{algpseudocode}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Bring in and examine the data

## Bring in both the train and the test data
```{r}
 # BRING IN THE DATA
train <- read.table(file=
"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra",
sep=",", header = FALSE, na.strings = c("NA", "", " "),
col.names = c(paste("x", 1:64, sep=""), "digit"))
test <- read.table(file=
"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes",
sep=",", header = FALSE, na.strings = c("NA", "", " "),
col.names = c(paste("x", 1:64, sep=""), "digit"))

dim(train)
dim(test)
```


## Checking for columns that are unary or close to unary
```{r, warning=FALSE,  message=FALSE}
library(caret)
nearZeroVar(train[,-65], uniqueCut = 10, saveMetrics = TRUE)
nearZeroVar(train[,-65], names = TRUE)
```

```{r, warning=FALSE,  message=FALSE}
library(caret)
nearZeroVar(test[,-65], uniqueCut = 10, saveMetrics = TRUE)
nearZeroVar(test[,-65], names = TRUE)
```


```{r}
train <- train[,-c(1,8,9,16,17,24,25,32,33,40,41,48,49,56,57,64)]

test <- test[,-c(1,8,9,16,17,24,25,32,33,40,41,48,49,56,57,64)]
```

\ 

Remarks

I removed the columns 1,8,9,16,17,24,25,32,33,40,41,48,49,56,57,64 from the
columns of both train and test data since they have some values that are unary
and some close to unary. 


## Checking for missing values
```{r}
library(questionr)
freq.na(train)
```


\ 

Remarks

There are no missing values in the train data.


# Ordinary Principal Components Analysis (PCA) 

```{r}

# Parallel Boxplot of the attributes of the train data
boxplot(train[,-49], col = rainbow(ncol(train[,-49])), main="Boxplot of train data")


# Parallel Boxplot of the attributes of the test data
boxplot(test[,-49], col = rainbow(ncol(test[,-49])), main="Boxplot of test data")
```

\

Remarks

- Majority of the predictors in both the train and test data have unequal range 
and unequal variation. 
- Hence,scaling is necessary for some modeling approaches.


```{r}
# scaling the train and test data
train_scaled <- data.frame(apply(train[,-49], 2, scale,center=T, scale=T)) 
  
mean <- apply(train_scaled, 2, mean)
sd <-  apply(train_scaled, 2, sd)
test_scaled <- data.frame(scale(test[, -49], center = mean, scale = sd))
  
```


```{r}
boxplot(train_scaled, col = rainbow(ncol(train_scaled)), main="Boxplot of  standardized train data")
boxplot(test_scaled, col = rainbow(ncol(test_scaled)), main="Boxplot of standardized test data")
```


\

Remarks

After scaling both the test and train data, we see that very few of the attributes of test and train data have unequal range and variation. 
Hence,we can now run the ordinary principal components analysis (PCA).


```{r}
pca <- prcomp(train_scaled, retx=TRUE, center=F, scale=F)

# OBTAIN EIGENVALUES 
lambda <- eigen(cov(train_scaled), only.values = T)$values
lambda
```


```{r}
#screeplot of variance
screeplot(pca, npcs = 30,  type="lines", main="Scree Plot", col = "red")
```



```{r}
# PLOT FIRST TWO PCs
par(mfrow=c(1,1), mar=rep(4,4))
plot(pca$x[,1:2], pch="", main="PC.1 and PC.2 for the train handwritten digit data")
text(pca$x[,1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


\

Remarks

We can see from the plot graph that the first two PCs fairly successfully 
separate the digits. We see, for instance, that most 6s lie on the top of
the plot, most 4s lie on the upper right, most 7s on the bottom right, and most 2s on the middle-top left. There are however regions of overlap.

# Kernel PCA


```{r}
# Using different kernel functions 
library(kernlab)
kernel_pca1 <- kpca(~., data=train_scaled, kernel="rbfdot", kpar=list(sigma=0.01),features = 10)

kernel_pca2 <- kpca(~., data=train_scaled, kernel="vanilladot",kpar=list(),
                    features = 10)
kernel_pca3 <- kpca(~.,data=train_scaled, kernel="polydot", kpar=list(degree=2),
                    features=10)
kernel_pca4 <- kpca(~.,data=train_scaled,kernel="laplacedot",
                    kpar=list(sigma=0.01),features=10)

```


```{r}
# Get the variance of each kernel pca.
var.pc1 <- eig(kernel_pca1)
var.pc2 <- eig(kernel_pca2)
var.pc3 <- eig(kernel_pca3)
var.pc4 <- eig(kernel_pca4)
variance <- data.frame(var.pc1, var.pc2, var.pc3, var.pc4)
variance
```




- Plotting the first two PCs for each of the kernel pca

```{r}
PC1 <- rotated(kernel_pca1)    # returns the data projected in the (kernel) pca space
plot(PC1[, 1:2],col=train$digit, pch="",
     main="KPC.1 and KPC.2 for the train handwritten digit data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC1[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


```{r}
PC2 <- rotated(kernel_pca2)    # returns the data projected in the (kernel) pca space
plot(PC2[, 1:2],col=train$digit, pch="",
     main="KPC.1 and KPC.2 for the train handwritten digit data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC2[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


```{r}
PC3 <- rotated(kernel_pca3)    # returns the data projected in the (kernel) pca space
plot(PC3[, 1:2],col=train$digit, pch="",
     main="KPC.1 and KPC.2 for the train handwritten digit data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC3[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


```{r}
PC4 <- rotated(kernel_pca4)    # returns the data projected in the (kernel) pca space
plot(PC4[, 1:2],col=train$digit, pch="",
     main="KPC.1 and KPC.2 for the train handwritten digit data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC4[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


\

Remarks

We observed that the kernel pca using the vanilladot kernel function separated or clustered the digits well as compared to the other kernel
pca's using different kernel functions. So, I choose the kernel pca using 
the vanilladot kernel function.



```{r}
#screeplot for the variance of the kernel pca using vanilladot.
var.pc <- eig(kernel_pca2)
prop.pc <- var.pc/sum(var.pc)
plot(prop.pc, xlab = "Principal Component", col = "red",
	ylab = "Proportion of Variance Explained", type = "b", pch = 19)
```


```{r}
# Plot THE DATA PROJECTION ON THE KERNEL PCS 
PC <- rotated(kernel_pca2)    # returns the data projected in the (kernel) pca space
plot(PC[, 1:2],col=train$digit, pch="",
     main="KPC.1 and KPC.2 for the train handwritten digit data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```



\
 
Remarks
 

- We can see from the above plots that the first two PCs fairly successfully separate the digits. We see, for instance, that most 6s lie on the top of the plot, most 4s on the top left, most 7s on the bottom and most 2s lie on the middle right.There are however regions of overlap.

- The choice of kernel function used is vanilladot(linear kernel function).
- The parameter is degree $= 1$.
  
 

- comparison of PCA and KPCA

```{r}
par(mfrow=c(1,2), mar=rep(4,4))
plot(pca$x[,1:2], pch="", main="Ordinary PCA for the train data")
text(pca$x[,1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)


plot(PC[, 1:2],col=train$digit, pch="",
     main="Kernel PCA for the train data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```


\ 

Remarks

We see from the above plots that there is no significant difference between clustering of the digits.
Both methods show that the first two PCs explain a substantial portion of the variation in the data. 


# PCA and KPCA on the test data

```{r}
#ordinary pca
pred_pca <- predict(pca, test_scaled)

# comparison of the PCA  results on the train and test data

par(mfrow=c(1,2), mar=rep(4,4))
plot(pca$x[,1:2], pch="", main="Ordinary PCA on train data")
text(pca$x[,1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)


plot(pred_pca[,1:2], pch="", main="Ordinary PCA on test data")
text(pred_pca[,1:2], labels=test$digit, col= test$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)

```


\

Remarks

There is no significant difference between ordinary pca on both the train and test data.


```{r}
#kernel pca
pred_kernel_pca <- predict(kernel_pca2, test_scaled)

par(mfrow=c(1,2), mar=rep(4,4))
plot(PC[, 1:2],col=train$digit, pch="",
     main="Kernel PCA on train data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(PC[, 1:2], labels=train$digit, col= train$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)


plot(pred_kernel_pca[, 1:2],col=test$digit, pch="",
     main="Kernel PCA on test data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(pred_kernel_pca[, 1:2], labels=test$digit, col= test$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)

```


\

Remarks

There is no significant difference between the result of the Kernel pca on the train data and the kernel pca on test data.


- comparison of ordinary pca and kernel pca on the test data
```{r}
par(mfrow=c(1,2), mar=rep(4,4))

plot(pred_pca[,1:2], pch="", main="Ordinary PCA on test data")
text(pred_pca[,1:2], labels=test$digit, col= test$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)

plot(pred_kernel_pca[, 1:2],col=test$digit, pch="",
     main="Kernel PCA on test data",
     xlab="1st Kernel PC", ylab="2nd Kernel PC")
text(pred_kernel_pca[, 1:2], labels=test$digit, col= test$digit)
abline(v=0, lty=2)
abline(h=0, lty=2)
```



\

Remarks

- There is no signifcaant difference betweeen thee results of the ordinary
pca and the kernel pca on the test data.

- We observe that most 2s lie on the middle left on the ordinary pca while they lie on the middle right on the kernel pca.

- In both cases they fairly separate the digits well.




# ASSOCIATION RULES

## Read in Data
```{r}
library(arules)
bible <- read.transactions(file="AV1611Bible.txt",
format = "basket", sep =" ", rm.duplicates =F,
quote="") # DOUBLE/SINGLE QUOTE ISSUE
dat <- bible; dim(dat)
inspect(dat[1:5, ])
```



## Perform frequent itemsets and association rule analysis.

```{r}
# The first 15 items (frequency/support)
itemFrequency(dat[, 1:15])
```


```{r}
# Plot items with high frequencies. 
itemFrequencyPlot(dat, topN=10, support = 0.01, cex.names = 0.8, col="blue")
```

\

Remarks

We observe that lord has the highest frequency.


```{r}
summary(dat)
```

\

Remarks

- Itemset/transaction with size 9 has the highest frequency of 2611

- Itemset/transaction with the highest size 37 and size 32 have the lowest frequency of 2.




```{r}
#Association Rule Analysis
rules <- apriori(dat, parameter = list(support = 0.01, confidence = 0.5, 
	target = "rules", maxlen=5))
inspect(rules[1:5])
```


```{r}
Rules <- as(rules, "data.frame")
head(Rules); tail(Rules)
dim(Rules)
```



```{r}
inspect(rules[1:10], ruleSep = "---->", itemSep = " + ", setStart = "",
        setEnd ="",linebreak = FALSE)
```



```{r}
quality(rules[1:15])
```


```{r}
summary(rules)
```

\ 

Remarks

- The parameters used for the R function arules are : 
support = 0.01,confidence = 0.5,target = "rules",maxlen=5.

- The maximum support is 0.03900  and the minimum support is 0.01055.

- The maximum confidence is 1.0000  and the minimum confidence is 0.5012.

- The maximum lift is 22.183   and the minimum lift is 2.517. 


## Top 5 rules in decreasing order of confidence (conf) for item sets of size/length 2 or 3. 
```{r}
rules0 <- data.frame(matrix(unlist(strsplit(as.character(Rules$rules), split="=>")), 
	ncol=2, byrow=TRUE))
colnames(rules0) <- c("LHS", "RHS")
rule.size <- function(x){length(unlist(strsplit(as.character(x), split=",")))}
rules0$size <- apply(rules0, 1, rule.size)
```

```{r}
z <- data.frame(Rules, size=rules0$size)
top.support <- z[order(z$confidence, decreasing = T),]
head(top.support, 5)  
```

\

Remarks

We observed that the rule (shalt) $=>$ (thou) is a creditable rule since it has a large level of support(0.03900196),large confidence(0.9991763) factor and a value of lift(8.007055) greater than 1. Thus, we expect to see **shalt** followed by **thou** in the King James Bible1.
In other words, shalt and thou are words that commonly occur together in sentences.


## Top 5 rules in decreasing order of the lift measure for item sets of size 2 or 3.
```{r}
z <- data.frame(Rules, size=rules0$size)
top5.lift <- z[order(z$lift, decreasing = T),]
head(top5.lift, 5)
```



\

Remarks

We observed that the rule (thus) $=>$ (saith) is a fairly a creditable rule since it has a fairly large level of support(0.01462975),fairly large confidence(0.6435644) factor and a value of lift(16.721383) greater than 1. Hence, thus and saith are words that commonly occur together in sentences in the King James Bible.


## Conviction measures for the top-lift 5 rules in Part (d)
```{r}
top5_liftrules <- sort(rules, decreasing = T, by='lift')[1:5,] # top lift 5 rules
interestMeasure(top5_liftrules, "conviction", transactions = dat)
```

\

Remarks

- The problem associated with both the confidence and the lift
measures is that they are not sensitive to rule direction.
On the other hand, conviction is sensitive to rule direction. It attempts to measure the degree of implication of a rule. That is unlike lift,
conviction($A => B$) $\ne$ conviction($B => A$).

- The conviction((shalt,thee) $=>$ (thou)) $=$ $\infty$ . This is because  the confidence obtained for the rule (shalt,thee) $=>$ (thou) in part b is 1.



